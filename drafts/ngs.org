#+TITLE:        RNA-Seq Workshop
#+LANG:         en
#+STARTUP:      align fold noindent hideblocks fnlocal
#+OPTIONS:      H:3 num:nil toc:2 ':t *:t ::t f:t |:t -:t

* TODO [2/8] :noexport:
- [X] "How many reads map onto exons, introns and intergenic regions" on [[https://www.biostars.org/p/131734/][Biostars]]
- [ ] [[http://clavius.bc.edu/~erik/CSHL-advanced-sequencing/freebayes-tutorial.htm][Calling variants with freebayes]]
- [ ] https://github.com/CBC-UCONN/Variant-Calling-with-Samtools
- [X] [[https://is.gd/q5umF6][RPKM, FPKM and TPM, clearly explained]]
- [ ] [[https://www.bioconductor.org/packages/devel/workflows/vignettes/rnaseqGene/inst/doc/rnaseqGene.html][RNA-seq workflow: gene-level exploratory analysis and differential expression]]
- [ ] [[http://lab.loman.net/2012/10/31/a-simple-guide-to-variant-calling-with-bwa-samtools-varscan2/][A simple guide to variant calling with BWA, samtools, VarScan2]]
- [ ] [[https://digibio.blogspot.com/2017/11/rna-seq-analysis-hisat2-featurecounts.html][RNA seq analysis - FeatureCounts and DESeq2 workflow]]
- [ ] [[https://4va.github.io/biodatasci/r-rnaseq-airway.html][Count-Based Differential Expression Analysis of RNA-seq Data]]

* Introduction
** Processing steps

Overall, RNA-Seq analysis consists in a series of extraction, preprocessing and statistical analysis:

1. DNA extraction from a sample
2. DNA sequencing
3. Alignment of sequencing reads to a reference genome
4. Basic exploratory data analysis
5. Identification of genomic variants (SNPs, small insertions and deletions)
6. Gene quantification (i.e., statistics on count data)

Some reviews of best practices are available [@conesa-2016-survey-best; @yendrek-2012-bench-scien]. Regarding statistical software, the state of the art is described on the [[https://www.bioconductor.org][Bioconductor]] project [@korpelainen-2015-rna; @anders-2013-count-rna].

#+CAPTION: Typical workflow (From @anders-2013-count-rna)
#+ATTR_LaTeX: scale=0.75
#+LABEL: fig:count-rna
[[./_img/fig-count-rna.png]]

** Tools

There are many, many tools available on the internet. They are mostly open-source and macOS-compatible. To name a few:

- [[https://github.com/ucdavis-bioinformatics/sickle][sickle]], for QC of reads
- [[http://cole-trapnell-lab.github.io/cufflinks/][cufflinks]], part of the Tuxedo toolsuite (Bowtie + TopHat + cufflinks)
- [[https://broadinstitute.github.io/picard/][Picard]], to manipulate HTS files
- [[http://bowtie-bio.sourceforge.net/bowtie2/index.shtml][Bowtie2]], or [[https://ccb.jhu.edu/software/tophat/index.shtml][TopHat2]] which relies on Bowtie, now [[https://ccb.jhu.edu/software/hisat2/index.shtml][HISAT2]] (3), for alignments
- [[https://pachterlab.github.io/kallisto/][kallisto]] (faster), for fast alignment
- [[http://www.htslib.org/download/][SAMtools]] (4+5)
- [[https://www.htslib.org/doc/bcftools.html][BCFtools]] (not to be confounded with [[https://bedtools.readthedocs.io/en/latest/][bedtools]])
- [[https://github.com/vcflib/vcflib][vcflib]], to manipulate VCF files
- bedtools [[https://bedtools.readthedocs.io/en/latest/content/tools/multicov.html][multicov]], featureCounts ([[http://subread.sourceforge.net][subread]]), [[https://htseq.readthedocs.io/en/release_0.11.1/][HTSeq]]

Most tools are also available in Galaxy (e.g., [[https://usegalaxy.eu][Galaxy Europe]], or as "shed tools" on a dedicated Galaxy server). Another software that is widely used for RNA-Seq analysis is [[http://mev.tm4.org/][MeV]], but this a web application only, see @howe-2011-rna-seq-mev.

* Applications
** Kallisto + DESeq2

Whether we use Galaxy or the command-line, we basically need two kind of files: a reference genome (Fasta) and Fastq or sra reads files. If reads are in SRA format, they need to be converted to Fastq format using the =sratoolkit=. For gene quantification using =DESeq2=, we will further need annotation as a GFF or GFF3 file.

Kallisto will produce counts and TPM values in a TSV file (as well as an HDF5 file). Here is an example of Kallisto output:

#+BEGIN_EXAMPLE Kallisto abundance data
target_id       length  eff_length      est_counts      tpm
jgi|Podans1|100005|CE99640_2373 1994    1895    1407    51.6298
jgi|Podans1|100060|CE99695_1372 3146    3047    504     11.502
jgi|Podans1|10015|CE9650_8706   1582    1483    1156    54.2042
#+END_EXAMPLE

Note that transcript ID (taken from the reference genome, =>jgi|Podans1|100005|CE99640_2373=) should correspond to gene ID in the annotation file, which actually reads:

#+BEGIN_EXAMPLE Annotation file
##gff-version 3
-%<-----
38763:scaffold_3	prediction	gene	644807	646915	0	+	.	ID=gene_5098;Name=jgi.p|Podans1|99641;portal_id=Podans1;product_name=Cytochrome P450;proteinId=99641;transcriptId=100005
38764:scaffold_3	prediction	mRNA	644807	646915	.	+	.	ID=mRNA_5098;Name=jgi.p|Podans1|99641;Parent=gene_5098;proteinId=99641;track=FilteredModels1;transcriptId=100005
#+END_EXAMPLE

In this case, this means that the transcript ID 100005 is found in unexpected place: when using Galaxy, you will have to update the corresponding ID.[fn:fixid]

Basically, NGS analyses (RNA, CHIP, etc.) need to account for within-group variance estimates when analysing lot of genes, hence the need to pool information across genes. The DESeq approach detects and corrects dispersion estimates that are too low through modeling of the dependence of the dispersion on the average expression strength over all samples. In addition, it provides a novel method for gene ranking and the visualization of stable estimates of effect sizes [@love-2014-moder-rna-deseq]. The [[https://bioconductor.org/packages/release/bioc/html/DESeq2.html][DESeq2]] package further includes shrunken fold changes (with SE).

We need two data frames before running the statistical analysis: a table of counts (or TPM values from =kallisto= or =salmon=), and a table describing the experimental condition. Note that each run must come as triplicate. Here are the basic steps to import counts data and setup the design matrix:

#+BEGIN_SRC R
library("DESeq2")
library("tximport")

datadir <- dir(".", pattern = "out.\\.*")
files <- file.path(datadir, "abundance.h5")
names(files) <- gsub("out.", "", datadir)
samples <- data.frame(run = names(files), condition = c("4h", "48h", "24h"))

txi <- tximport(files, "kallisto", txOut = TRUE)

dds <- DESeqDataSetFromTximport(txi, colData = samples, design = ~ condition)
#+END_SRC

[fn:fixid] An R [[file:src/rewrite_gff3.r][script]] can be used to process the original GFF file and update ID so that they match each other.

** TopHat + HTSeq (or FeatureCounts)

This workflow usually takes a longer time but TopHat has the advantage of being aware of splice junction (in fact, this is what TopHat really adds to bowtie).

** Statistical analysis of count data

*** Sanity checks

Two preprocessing stages are worth considering before dwelling into gene quantification /per se/: quality control and normalization. Quality control amounts to controlling the number of genes having non-zero counts in all samples. If this number is very low, it is likely that something went wrong, at least with some of the samples. Based on the DESeq table of counts, we can proceed as follows in R:

#+BEGIN_SRC R
gene_counts <- counts(dds)
counts_per_sample <- apply(gene_counts, 1, function(x) all(x) > 0)
cat(sum(counts_per_sample), "out of", nrow(dds), "\n")
#+END_SRC

Normalization refers to the comparison of size factors defined as the median of ratios of each sample to a virtual reference sample (median of each gene’s values across samples). Those ratios are expected to match the ratios of the library sizes and be roughly equal to one. Dividing each column of the count table by the corresponding size factor yields normalized count values, which can be scaled to give a counts per million interpretation.

The MA plot shows the average vs mean–difference of log fold change, centered around 0, and it is expected to observe higher variability of log ratios at lower counts.

*** Sample clustering

A PCA or simple heatmap of the results of hierarchical clustering of the sample data can be used to assess overall similarity between samples. We expect triplicate to cluster together while samples from very different experimental conditions are expected to be far away one from the other. Of note, it is useful to apply a regularized log–transformation on the raw counts to avoid the impact of few highly variale genes, hence considering a roughly equal contribution from all genes.

* Appendix
** Tutorials

- Workflows: https://is.gd/eKFGC2 + https://is.gd/In1Zcn
- [[https://osca.bioconductor.org][Orchestrating Single-Cell Analysis with Bioconductor]]
- https://bioinformatics.uconn.edu/reference-based-rna-seq-data-analysis/ (Galaxy)
- https://gitlab.com/cbc-uconn/prokaryote_rnaseq
- https://gitlab.com/cbc-uconn/model_marine_rnaseq_and_functional_annotation_uconn/blob/master/README.md
** File Formats

Fasta files contain nucleotide or aa, with a description line (the symbol =>= followed by the sequence /identifier/ and other (optional) information, also called /comment/). File extension is usually =.fasta=, =.fa=, or =.faa= (amino acid) and =.fna= (nucleotides).

Most bioinformatics software allow to read Fasta file in an efficient manner. Don't try to write your own reader unless you know what you are doing. E.g., in Python, you can use the [[https://biopython.org][BioPython]] module:

#+BEGIN_SRC python
from Bio import SeqIO

records = list(SeqIO.parse("sordariales-all.fa", 'fasta'))
#+END_SRC

Fastq files are like Fasta file (header = =@= followed by sequence ID) but with the corresponding quality scores on a separate line (after the =+= sign). Quality value ranges from 0x21 (!, lowest) to 0x7e (~, highest). Like Fasta files, they can be compressed using =gzip=. Extension is usually =.fastq= or =.fq=. Beware of differing rules (offset coding and PHRED scores) between Sanger and Illumina Fastq format. Here is an example of the first of the four lines available in each entry of a Fastq file:

#+BEGIN_EXAMPLE Fastq file
@K00188:208:HFLNGBBXX:3:1101:1428:1508 2:N:0:CTTGTA
#+END_EXAMPLE

The interesting part in the above example are =2:N:0:CTTGTA=, which stands for the member of a pair (1 or 2, for paired-end or mate-pair reads only), the filter status (Y if filtered, N otherwise), the control bits (0 when none, otherwise if they are on), and the index sequence or barcode (=CTTGTA=).

Together with SRA format (see below), this is the default format for DNA reads. Quality control on the reads can be performed using, e.g., =sickle=, which basically allows to filter reads with low quality, e.g., PHRED score < 35:[fn:phred]

#+BEGIN_SRC bash
$ sickle se -f SRR391535.fastq -t sanger -o trimmed_SRR391535.fastq -q 35 -l 45
#+END_SRC

This is often one of the very first pre-processing step when working with a batch of DNA reads.

The SRA format is used for Sequence Read Archives, from NCBI. They can be converted to Fastq using =fastq-dump=:

#+BEGIN_SRC bash
$ fastq-dump --gzip file.sra
#+END_SRC

As an alternative, =samtools= can be used to generate a BAM file:

#+BEGIN_SRC bash
$ sam-dump SRR6960207.sra \
    | samtools view -bS - > alignments/SRR6960207.bam
#+END_SRC

SAM (BAM) files are composed of a header (=@= lines) and alignments of the sequence against a reference genome. BAM files are compressed version of SAM files, and you will need the =samtools= to display them on screen.

#+CAPTION: Sequence Alignment/Map Format Specification
#+ATTR_LaTeX: scale=0.75
#+NAME: fig:sam-format
[[./_img/fig-sam-format.png]]

VCF stands for Variant Call(ing) Format (See [[http://www.1000genomes.org][1000 Genomes Project]]). The format is standardized, like for SAM files:

#+BEGIN_EXAMPLE Header of a VCF file
#CHROM, POS, ID, REF, ALT, QUAL, FILTER, INFO.
#+END_EXAMPLE

A typical workflow consists in calling =mpileup= via =samtools= or =bcftools= (which now integrate the pileup option). The =mpileup= command automatically scans every position supported by an aligned read, computes all the possible genotypes supported by these reads, and then computes the probability that each of these genotypes is truly present in our sample.

#+BEGIN_SRC bash
$ bcftools mpileup -f NC_008253.fna reads_aligned.sorted.bam -o sim_variants.bcf
#+END_SRC

The =vcflib= tools allow to further manipulate VCF files (comparison, format conversion, /filtering/ and subsetting, annotation, samples, ordering, variant representation, genotype manipulation, interpretation and classification of variants)

Finally, GFF (or GFF3) files, which stand for General Feature Format or Gene Finding Format, are used to provide a list of the features (CDS, gene, etc.) available on a given sequence. They have 9 mandatory TAB separated columns. GFF3 have extension =.gff3=. A typical file is shown below:

#+BEGIN_EXAMPLE GFF3 format
##gff-version 3
ctg123 . mRNA           1300 9000 . + . ID=mrna0001;Name=sonichedgehog
ctg123 . exon           1300 1500 . + . ID=exon00001;Parent=mrna0001
ctg123 . exon           1050 1500 . + . ID=exon00002;Parent=mrna0001
ctg123 . exon           3000 3902 . + . ID=exon00003;Parent=mrna0001
ctg123 . exon           5000 5500 . + . ID=exon00004;Parent=mrna0001
ctg123 . exon           7000 9000 . + . ID=exon00005;Parent=mrna0001
#+END_EXAMPLE

Be careful with how entites are identified. In the above case, the id is called =ID=, but Galaxy expects =gene_id=, for example.

[fn:phred] The PHRED score is defined as $Q=-10\log_{10}(p)$ where where $p$ is the probability that the corresponding base call is incorrect. A score of 10 means a probability of 1/10 (hence, 90% accuracy for base calling), while a score of 30 means a probability of 1/1000.

* References
